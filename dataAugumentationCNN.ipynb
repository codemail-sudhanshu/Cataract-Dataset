{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codemail-sudhanshu/Cataract-Dataset/blob/main/dataAugumentationCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZEbnHfSP-IZ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRECerDIRy_a"
      },
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0agRU3M0NaMf"
      },
      "source": [
        "# from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, \n",
        "from tensorflow.keras.utils import img_to_array , array_to_img\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "# from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from keras.applications import ResNet50\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWXTGJvETqTp",
        "outputId": "d5e8b761-daaa-40b5-d1c4-bcec772d4e2f"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Deep Learning Models\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "sq_model.h5\n",
            "SQUEEZENET.docx\n",
            "vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rn0RQy2PAab",
        "outputId": "e274c510-fb41-43e2-f2bc-45150c4d31ca"
      },
      "source": [
        "#Training and testing directories\n",
        "train = 'TRAIN_DIR/'\n",
        "test = 'TEST_DIR/'\n",
        "\n",
        "#Augumentation with only zoom and grayscale format\n",
        "\n",
        "train_datagen2 = ImageDataGenerator(horizontal_flip=True, \n",
        "                             vertical_flip = True,\n",
        "                             zoom_range = 0.3,\n",
        "                             rescale=1/255.0\n",
        "                            )\n",
        "\n",
        "#Corresponding generator\n",
        "train_generator2 = train_datagen2.flow_from_directory(\n",
        "    train,\n",
        "    color_mode='grayscale',\n",
        "    target_size = (128,128),\n",
        "    batch_size=32,\n",
        "    class_mode = 'categorical',\n",
        "    seed=42)\n",
        "\n",
        "#ImageDataGenerator for testing/validation data\n",
        "\n",
        "test_datagen2 = ImageDataGenerator(\n",
        "     rescale=1/255.0 )\n",
        "#Using testing data as validation data\n",
        "\n",
        "validation_generator2 = test_datagen2.flow_from_directory(\n",
        "    test,\n",
        "    color_mode='grayscale',\n",
        "    batch_size=32,\n",
        "    target_size = (128,128),\n",
        "    class_mode = 'categorical',\n",
        "    seed=42 )\n",
        "\n",
        "x_train,y_train = next(train_generator2)\n",
        "x_test,y_test = next(validation_generator2)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 410 images belonging to 3 classes.\n",
            "Found 140 images belonging to 3 classes.\n",
            "(32, 128, 128, 1)\n",
            "(32, 128, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yexILKgTPRdl"
      },
      "source": [
        "#Basic CNN Model\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPool2D\n",
        "import numpy as np\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHxiNuJ3XrVE"
      },
      "source": [
        "checkpoint_filepath = 'checkpoint/'\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpEzpScmPXfh"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3),padding='same', activation='relu', input_shape = (128, 128, 1)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfVv-6n8Pfcv",
        "outputId": "24b954a0-d3a9-42d8-fe6b-5b1a92470019"
      },
      "source": [
        "#for fitting the model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "stop = EarlyStopping(\n",
        "    monitor = 'val_accuracy',\n",
        "    mode='max',\n",
        "    patience= 8,\n",
        "    verbose = 2,\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "STEPS = train_generator2.samples//train_generator2.batch_size\n",
        "VAL_STEPS = validation_generator2.samples//validation_generator2.batch_size\n",
        "EPOCHS = 20\n",
        "\n",
        "results = model.fit(\n",
        "train_generator2,\n",
        "steps_per_epoch=STEPS,\n",
        "epochs=EPOCHS,\n",
        "validation_data=validation_generator2,\n",
        "validation_steps=VAL_STEPS,\n",
        "callbacks=stop\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "12/12 [==============================] - 94s 9s/step - loss: 140.9354 - accuracy: 0.4630 - val_loss: 7.8532 - val_accuracy: 0.5469\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 2s 153ms/step - loss: 3.4570 - accuracy: 0.5238 - val_loss: 0.9715 - val_accuracy: 0.5938\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 2s 130ms/step - loss: 0.9277 - accuracy: 0.5212 - val_loss: 0.9670 - val_accuracy: 0.3750\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 0.8635 - accuracy: 0.5000 - val_loss: 0.9583 - val_accuracy: 0.3750\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 2s 132ms/step - loss: 0.8818 - accuracy: 0.5529 - val_loss: 0.8771 - val_accuracy: 0.4531\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 0.8592 - accuracy: 0.5212 - val_loss: 0.9018 - val_accuracy: 0.4062\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 2s 193ms/step - loss: 0.8862 - accuracy: 0.5661 - val_loss: 1.1221 - val_accuracy: 0.3281\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 2s 162ms/step - loss: 0.8338 - accuracy: 0.5794 - val_loss: 0.8868 - val_accuracy: 0.3984\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 2s 135ms/step - loss: 0.8128 - accuracy: 0.6250 - val_loss: 0.9422 - val_accuracy: 0.4062\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 2s 156ms/step - loss: 0.8075 - accuracy: 0.5873 - val_loss: 0.8612 - val_accuracy: 0.6094\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 2s 129ms/step - loss: 0.7952 - accuracy: 0.6111 - val_loss: 0.9396 - val_accuracy: 0.4141\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 2s 135ms/step - loss: 0.7957 - accuracy: 0.6138 - val_loss: 0.8352 - val_accuracy: 0.6016\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 0.7740 - accuracy: 0.6481 - val_loss: 0.8549 - val_accuracy: 0.5234\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 2s 188ms/step - loss: 0.7736 - accuracy: 0.6323 - val_loss: 0.7939 - val_accuracy: 0.6328\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 2s 167ms/step - loss: 0.7693 - accuracy: 0.6402 - val_loss: 0.8405 - val_accuracy: 0.5547\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 0.7499 - accuracy: 0.6349 - val_loss: 0.8391 - val_accuracy: 0.5703\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 2s 156ms/step - loss: 0.7583 - accuracy: 0.6190 - val_loss: 0.8158 - val_accuracy: 0.6484\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 2s 137ms/step - loss: 0.7545 - accuracy: 0.6376 - val_loss: 0.8093 - val_accuracy: 0.6250\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 0.7482 - accuracy: 0.6587 - val_loss: 0.8420 - val_accuracy: 0.6016\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 2s 131ms/step - loss: 0.7442 - accuracy: 0.6534 - val_loss: 0.8190 - val_accuracy: 0.6250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7jiku9IX9id"
      },
      "source": [
        "**Starting With ResNet50**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzyQi_GNYFti"
      },
      "source": [
        "from keras import applications\n",
        "from keras.models import Sequential,Model,load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
        "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint\n",
        "\n",
        "from keras.optimizers import SGD, Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tJVm-zeYL2C"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "base_model = ResNet50(weights= None, include_top=False, input_shape= (128,128,1))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(3, activation= 'softmax')(x)\n",
        "resnetmodel = Model(inputs = base_model.input, outputs = predictions)\n",
        "adam = Adam(lr=0.001)\n",
        "resnetmodel.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18jMTHo7Yn2m",
        "outputId": "58f1fabf-4953-4ac2-9ebe-6e58684d6a81"
      },
      "source": [
        "EPOCH = 30\n",
        "stopping_resNet = EarlyStopping(\n",
        "    monitor='val_accuracy', \n",
        "    mode='max',\n",
        "    patience=5,\n",
        "    verbose = 2,\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "restNetModel = resnetmodel.fit(\n",
        "    train_generator2,\n",
        "    steps_per_epoch=STEPS,\n",
        "    epochs=EPOCH,\n",
        "    validation_data=validation_generator2,\n",
        "    validation_steps=VAL_STEPS,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "4/4 [==============================] - 12s 739ms/step - loss: 1.2465 - accuracy: 0.8241\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 1s 150ms/step - loss: 4.8554e-06 - accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 1s 119ms/step - loss: 2.2076e-09 - accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 1s 122ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 1s 127ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 1s 128ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 1s 123ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 1s 120ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 1s 121ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 1s 122ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 1s 118ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 1s 144ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 1s 119ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 1s 143ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 1s 120ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 1s 110ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 1s 124ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 1s 121ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 1s 154ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 1s 156ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 1s 192ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 1s 106ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 1s 133ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 1s 106ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 1s 105ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 1s 104ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 1s 107ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 1s 119ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 1s 124ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 1s 145ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IKvETRu_0hH"
      },
      "source": [
        "Simple CNN with **1 Conv Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIumM69HJW1E"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es9z_PnVJhXP",
        "outputId": "0c0febbb-253f-4dee-963f-8559a2ca18c1"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "#1-conv layer\n",
        "model.add(Conv2D(64, (3,3), padding = 'same', input_shape=(128, 128,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 64)      640       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128, 128, 64)     256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 64, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 262144)            0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               33554560  \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,556,355\n",
            "Trainable params: 33,555,971\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koS1fPJJJ7Qg",
        "outputId": "acf2ad38-9422-415e-c812-de3fa5cb0c2e"
      },
      "source": [
        "STEPS = train_generator2.samples//train_generator2.batch_size\n",
        "VAL_STEPS = validation_generator2.samples//validation_generator2.batch_size\n",
        "EPOCHS = 20\n",
        "\n",
        "results = model.fit(\n",
        "train_generator2,\n",
        "steps_per_epoch=STEPS,\n",
        "epochs=EPOCHS,\n",
        "validation_data=validation_generator2,\n",
        "validation_steps=VAL_STEPS\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "12/12 [==============================] - 5s 155ms/step - loss: 1.2224 - accuracy: 0.5079 - val_loss: 1.5984 - val_accuracy: 0.3125\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 2s 134ms/step - loss: 0.7569 - accuracy: 0.7037 - val_loss: 0.8941 - val_accuracy: 0.6172\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 2s 137ms/step - loss: 0.6278 - accuracy: 0.7434 - val_loss: 0.9242 - val_accuracy: 0.7422\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 2s 139ms/step - loss: 0.5488 - accuracy: 0.7672 - val_loss: 0.9452 - val_accuracy: 0.5703\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 2s 137ms/step - loss: 0.5141 - accuracy: 0.7910 - val_loss: 1.0693 - val_accuracy: 0.4297\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 2s 165ms/step - loss: 0.4234 - accuracy: 0.8439 - val_loss: 1.1676 - val_accuracy: 0.4062\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 2s 179ms/step - loss: 0.3612 - accuracy: 0.8677 - val_loss: 1.3606 - val_accuracy: 0.4062\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 2s 135ms/step - loss: 0.4045 - accuracy: 0.8646 - val_loss: 1.6791 - val_accuracy: 0.3828\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 2s 133ms/step - loss: 0.4037 - accuracy: 0.8598 - val_loss: 1.7072 - val_accuracy: 0.3828\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 2s 136ms/step - loss: 0.4064 - accuracy: 0.8386 - val_loss: 1.7091 - val_accuracy: 0.4219\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 2s 139ms/step - loss: 0.3459 - accuracy: 0.8651 - val_loss: 2.1565 - val_accuracy: 0.4062\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 2s 136ms/step - loss: 0.3269 - accuracy: 0.8624 - val_loss: 2.3191 - val_accuracy: 0.4062\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 2s 191ms/step - loss: 0.2853 - accuracy: 0.8995 - val_loss: 2.4060 - val_accuracy: 0.4141\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 2s 184ms/step - loss: 0.2830 - accuracy: 0.9101 - val_loss: 2.6262 - val_accuracy: 0.3750\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 2s 139ms/step - loss: 0.2864 - accuracy: 0.8995 - val_loss: 2.6117 - val_accuracy: 0.3984\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 2s 141ms/step - loss: 0.2643 - accuracy: 0.9048 - val_loss: 2.6400 - val_accuracy: 0.3984\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 2s 131ms/step - loss: 0.2842 - accuracy: 0.9021 - val_loss: 2.7842 - val_accuracy: 0.3984\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 2s 136ms/step - loss: 0.2437 - accuracy: 0.9141 - val_loss: 2.9116 - val_accuracy: 0.3906\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 2s 137ms/step - loss: 0.2789 - accuracy: 0.9101 - val_loss: 3.1819 - val_accuracy: 0.3984\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 2s 204ms/step - loss: 0.2795 - accuracy: 0.8783 - val_loss: 3.0005 - val_accuracy: 0.3984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5np75skQX9t",
        "outputId": "bdcca278-1540-44ec-c99d-d53b49b1b4cb"
      },
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "#1-conv layer\n",
        "model2.add(Conv2D(64, (3,3), padding = 'same', input_shape=(256, 256,1)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "#2-conv layer\n",
        "model2.add(Conv2D(128,(5,5),padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "\n",
        "#Flatten\n",
        "model2.add(Flatten())\n",
        "\n",
        "\n",
        "model2.add(Dense(256))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Dense(512))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "#output layer\n",
        "model2.add(Dense(3,activation='softmax'))\n",
        "\n",
        "opt = Adam(lr = 0.0001)\n",
        "model2.compile(optimizer=opt, loss='categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 256, 256, 64)      640       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 256, 256, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256, 256, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 128, 128, 64)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 128)     204928    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 128, 128, 128)    512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 128, 128, 128)     0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 64, 64, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 524288)            0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               134217984 \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,560,515\n",
            "Trainable params: 134,558,595\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-F05LLX6Q5jS",
        "outputId": "d68e5c1b-69d4-43ba-8672-9de05fa58b63"
      },
      "source": [
        "results_3layer = model2.fit(\n",
        "    x=train_generator2,\n",
        "    steps_per_epoch = STEPS,\n",
        "    epochs = EPOCHS,\n",
        "    validation_data = validation_generator2,\n",
        "    validation_steps = VAL_STEPS,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-1fc88bc6f87b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m results_3layer = model2.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_2/dense_6/MatMul' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-42-1fc88bc6f87b>\", line 1, in <cell line: 1>\n      results_3layer = model2.fit(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/core/dense.py\", line 241, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'sequential_2/dense_6/MatMul'\nMatrix size-incompatible: In[0]: [32,131072], In[1]: [524288,256]\n\t [[{{node sequential_2/dense_6/MatMul}}]] [Op:__inference_train_function_27060]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8F34oaRAXIm"
      },
      "source": [
        "**VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI3ePjUzAZQT",
        "outputId": "2756b9bb-0a40-4cb8-8f7b-94a87e9b5890"
      },
      "source": [
        "#For RGB images\n",
        "\n",
        "train_datagen = ImageDataGenerator(horizontal_flip=True, \n",
        "                             zoom_range = 0.3,\n",
        "                             rescale=1/255.0,\n",
        "                            )\n",
        "\n",
        "#Corresponding generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    target_size = (128,128),\n",
        "    class_mode = 'categorical',\n",
        "    seed=42)\n",
        "\n",
        "#ImageDataGenerator for testing/validation data\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "     rescale=1/255.0 )\n",
        "#Using testing data as validation data\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test,\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    target_size = (128,128),\n",
        "    class_mode = 'categorical',\n",
        "    seed=42 )\n",
        "\n",
        "x_train,y_train = next(train_generator)\n",
        "x_test,y_test = next(validation_generator)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 410 images belonging to 3 classes.\n",
            "Found 140 images belonging to 3 classes.\n",
            "(32, 128, 128, 3)\n",
            "(32, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNDOq_ltAuFd",
        "outputId": "fe462682-10b6-47ec-a18b-fa2a4e1012a8"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import layers\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "vgg16_weight_path = 'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "base_model=tf.keras.applications.vgg16.VGG16(\n",
        "    # include_top=False,\n",
        "    weights='imagenet',\n",
        "    include_top=False, \n",
        "    input_shape=(128,128,3,)\n",
        ")\n",
        "# base_model = VGG16(\n",
        "#     weights=vgg16_weight_path,\n",
        "#     include_top=False, \n",
        "#     input_shape=(128,128,3,)\n",
        "# )\n",
        "\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 3)                 24579     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,739,267\n",
            "Trainable params: 24,579\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCS1_m_-A66v",
        "outputId": "e7e29f3a-8c3f-4b75-d105-3e0b6ae1bca5"
      },
      "source": [
        "EPOCHS_VGG = 30\n",
        "STEPS = train_generator.samples//train_generator.batch_size\n",
        "VAL_STEPS = validation_generator.samples//validation_generator.batch_size\n",
        "\n",
        "VGG_STOP = EarlyStopping(\n",
        "    monitor='val_accuracy', \n",
        "    mode='max',\n",
        "    patience=10,\n",
        "    verbose = 2,\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=STEPS,\n",
        "    epochs=EPOCHS_VGG,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=VAL_STEPS,\n",
        "    callbacks=[VGG_STOP]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 8s 441ms/step - loss: 1.0514 - accuracy: 0.5053 - val_loss: 0.8264 - val_accuracy: 0.5703\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 4s 297ms/step - loss: 0.6773 - accuracy: 0.6958 - val_loss: 0.7676 - val_accuracy: 0.6250\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 3s 250ms/step - loss: 0.5286 - accuracy: 0.7831 - val_loss: 0.5962 - val_accuracy: 0.7344\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 3s 242ms/step - loss: 0.4191 - accuracy: 0.8360 - val_loss: 0.5688 - val_accuracy: 0.7969\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 4s 317ms/step - loss: 0.3466 - accuracy: 0.8783 - val_loss: 0.5568 - val_accuracy: 0.8047\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 3s 244ms/step - loss: 0.3070 - accuracy: 0.8968 - val_loss: 0.5905 - val_accuracy: 0.7109\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 3s 221ms/step - loss: 0.2857 - accuracy: 0.9074 - val_loss: 0.6201 - val_accuracy: 0.6875\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 3s 276ms/step - loss: 0.2728 - accuracy: 0.9048 - val_loss: 0.4983 - val_accuracy: 0.7969\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 3s 278ms/step - loss: 0.2370 - accuracy: 0.9180 - val_loss: 0.5509 - val_accuracy: 0.7812\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 3s 244ms/step - loss: 0.2151 - accuracy: 0.9339 - val_loss: 0.5183 - val_accuracy: 0.7656\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 3s 243ms/step - loss: 0.2178 - accuracy: 0.9233 - val_loss: 0.5518 - val_accuracy: 0.7422\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 3s 270ms/step - loss: 0.2151 - accuracy: 0.9392 - val_loss: 0.5118 - val_accuracy: 0.8203\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 4s 295ms/step - loss: 0.2074 - accuracy: 0.9180 - val_loss: 0.4550 - val_accuracy: 0.8594\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 3s 240ms/step - loss: 0.1682 - accuracy: 0.9471 - val_loss: 0.6026 - val_accuracy: 0.7578\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 3s 215ms/step - loss: 0.2114 - accuracy: 0.9323 - val_loss: 0.5713 - val_accuracy: 0.7500\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 3s 294ms/step - loss: 0.1660 - accuracy: 0.9524 - val_loss: 0.4110 - val_accuracy: 0.8359\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 3s 243ms/step - loss: 0.1582 - accuracy: 0.9471 - val_loss: 0.5444 - val_accuracy: 0.8047\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 3s 220ms/step - loss: 0.1725 - accuracy: 0.9471 - val_loss: 0.4612 - val_accuracy: 0.7656\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 3s 238ms/step - loss: 0.1571 - accuracy: 0.9630 - val_loss: 0.5093 - val_accuracy: 0.7734\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 3s 285ms/step - loss: 0.1364 - accuracy: 0.9630 - val_loss: 0.3976 - val_accuracy: 0.8125\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 3s 224ms/step - loss: 0.1416 - accuracy: 0.9609 - val_loss: 0.4891 - val_accuracy: 0.8047\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 3s 243ms/step - loss: 0.1491 - accuracy: 0.9418 - val_loss: 0.4735 - val_accuracy: 0.7734\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.9577Restoring model weights from the end of the best epoch: 13.\n",
            "12/12 [==============================] - 3s 224ms/step - loss: 0.1503 - accuracy: 0.9577 - val_loss: 0.4726 - val_accuracy: 0.7812\n",
            "Epoch 23: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8ej7-2E4E4a"
      },
      "source": [
        "Mobile Net **V2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gWRvfCV4IwI"
      },
      "source": [
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "from keras import layers\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam, RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOBaaFqD4SVK",
        "outputId": "7dea13da-6eae-456e-f7a6-46dfc68420ad"
      },
      "source": [
        "#Training and testing directories\n",
        "train = 'TRAIN_DIR/'\n",
        "test = 'TEST_DIR/'\n",
        "\n",
        "#For RGB images\n",
        "train_datagen = ImageDataGenerator(horizontal_flip=True, \n",
        "                             zoom_range = 0.3,\n",
        "                             preprocessing_function = preprocess_input)\n",
        "\n",
        "#Corresponding generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    class_mode = 'categorical',\n",
        "    target_size = (128,128),\n",
        "    seed=42)\n",
        "\n",
        "#ImageDataGenerator for testing/validation data\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function = preprocess_input\n",
        ")\n",
        "#Using testing data as validation data\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test,\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    class_mode = 'categorical',\n",
        "    target_size = (128,128),\n",
        "    seed=42 )\n",
        "\n",
        "x_train,y_train = next(train_generator)\n",
        "x_test,y_test = next(validation_generator)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 410 images belonging to 3 classes.\n",
            "Found 140 images belonging to 3 classes.\n",
            "(32, 128, 128, 3)\n",
            "(32, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFXWDY6q5A1P",
        "outputId": "ec5f7016-197c-4bff-994a-eb0da6b52e85"
      },
      "source": [
        "mobilenet_weight_path = 'mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5'\n",
        "\n",
        "mobileNet = tf.keras.applications.MobileNetV2(  input_shape = (128,128,3),alpha=1.0,include_top=False,weights='imagenet')\n",
        "# mobileNet = MobileNetV2(\n",
        "#     input_shape = (128,128,3),\n",
        "#     alpha=1.0,\n",
        "#     include_top=False,\n",
        "#     weights= mobilenet_weight_path\n",
        "# )\n",
        "\n",
        "MN_model = Sequential()\n",
        "MN_model.add(mobileNet)\n",
        "MN_model.add(layers.GlobalAveragePooling2D())\n",
        "MN_model.add(layers.Dropout(0.5))\n",
        "MN_model.add(layers.Dense(3, activation='softmax'))\n",
        "    \n",
        "MN_model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=Adam(lr=0.00002),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "MN_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_128 (Funct  (None, 4, 4, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 1280)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 3)                 3843      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,261,827\n",
            "Trainable params: 2,227,715\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndWVw-Ls5La0",
        "outputId": "68a23835-6df1-4c2d-f0b4-b815cda65078"
      },
      "source": [
        "#for fitting the model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "EPOCHS_MN = 30\n",
        "\n",
        "STEPS = train_generator.samples//train_generator.batch_size\n",
        "VAL_STEPS = validation_generator.samples//validation_generator.batch_size\n",
        "\n",
        "MN_STOP = EarlyStopping(\n",
        "    monitor='val_accuracy', \n",
        "    mode='max',\n",
        "    patience=7,\n",
        "    verbose = 2,\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "history = MN_model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=STEPS,\n",
        "    epochs=EPOCHS_MN,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=VAL_STEPS,\n",
        "    callbacks=[MN_STOP]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 12s 467ms/step - loss: 1.5280 - accuracy: 0.3360 - val_loss: 1.1590 - val_accuracy: 0.4297\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 3s 281ms/step - loss: 1.2058 - accuracy: 0.4709 - val_loss: 0.9906 - val_accuracy: 0.5000\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 3s 255ms/step - loss: 0.9514 - accuracy: 0.5608 - val_loss: 0.8914 - val_accuracy: 0.5469\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 4s 314ms/step - loss: 0.7221 - accuracy: 0.6878 - val_loss: 0.8706 - val_accuracy: 0.5469\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 3s 237ms/step - loss: 0.6295 - accuracy: 0.7370 - val_loss: 0.7932 - val_accuracy: 0.6172\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 3s 265ms/step - loss: 0.4675 - accuracy: 0.8360 - val_loss: 0.7013 - val_accuracy: 0.7188\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 4s 306ms/step - loss: 0.4025 - accuracy: 0.8598 - val_loss: 0.7519 - val_accuracy: 0.7109\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 4s 304ms/step - loss: 0.3199 - accuracy: 0.8889 - val_loss: 0.6916 - val_accuracy: 0.7344\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 3s 275ms/step - loss: 0.2579 - accuracy: 0.9259 - val_loss: 0.7046 - val_accuracy: 0.7266\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 4s 323ms/step - loss: 0.2711 - accuracy: 0.9021 - val_loss: 0.7074 - val_accuracy: 0.7266\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 3s 259ms/step - loss: 0.2064 - accuracy: 0.9339 - val_loss: 0.7354 - val_accuracy: 0.7266\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 3s 230ms/step - loss: 0.1743 - accuracy: 0.9524 - val_loss: 0.6942 - val_accuracy: 0.7344\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 3s 235ms/step - loss: 0.1718 - accuracy: 0.9524 - val_loss: 0.7790 - val_accuracy: 0.7188\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 4s 358ms/step - loss: 0.1695 - accuracy: 0.9524 - val_loss: 0.7376 - val_accuracy: 0.7344\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 3s 258ms/step - loss: 0.1417 - accuracy: 0.9524 - val_loss: 0.7600 - val_accuracy: 0.7422\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 4s 348ms/step - loss: 0.1387 - accuracy: 0.9661 - val_loss: 0.7956 - val_accuracy: 0.7109\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 3s 280ms/step - loss: 0.1544 - accuracy: 0.9603 - val_loss: 0.7523 - val_accuracy: 0.7422\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 3s 228ms/step - loss: 0.1196 - accuracy: 0.9630 - val_loss: 0.7668 - val_accuracy: 0.7344\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 3s 229ms/step - loss: 0.0814 - accuracy: 0.9788 - val_loss: 0.7236 - val_accuracy: 0.7422\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 3s 262ms/step - loss: 0.1167 - accuracy: 0.9656 - val_loss: 0.7166 - val_accuracy: 0.7500\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 4s 337ms/step - loss: 0.0771 - accuracy: 0.9788 - val_loss: 0.7351 - val_accuracy: 0.7500\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 3s 224ms/step - loss: 0.0905 - accuracy: 0.9762 - val_loss: 0.7223 - val_accuracy: 0.7500\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - 3s 263ms/step - loss: 0.1002 - accuracy: 0.9656 - val_loss: 0.7273 - val_accuracy: 0.7578\n",
            "Epoch 24/30\n",
            "12/12 [==============================] - 6s 453ms/step - loss: 0.0833 - accuracy: 0.9815 - val_loss: 0.7441 - val_accuracy: 0.7500\n",
            "Epoch 25/30\n",
            "12/12 [==============================] - 3s 250ms/step - loss: 0.0772 - accuracy: 0.9815 - val_loss: 0.6961 - val_accuracy: 0.7500\n",
            "Epoch 26/30\n",
            "12/12 [==============================] - 3s 285ms/step - loss: 0.0649 - accuracy: 0.9868 - val_loss: 0.6637 - val_accuracy: 0.7578\n",
            "Epoch 27/30\n",
            "12/12 [==============================] - 3s 255ms/step - loss: 0.0524 - accuracy: 0.9947 - val_loss: 0.7195 - val_accuracy: 0.7500\n",
            "Epoch 28/30\n",
            "12/12 [==============================] - 3s 261ms/step - loss: 0.0512 - accuracy: 0.9921 - val_loss: 0.6818 - val_accuracy: 0.7734\n",
            "Epoch 29/30\n",
            "12/12 [==============================] - 4s 325ms/step - loss: 0.0601 - accuracy: 0.9868 - val_loss: 0.6889 - val_accuracy: 0.7656\n",
            "Epoch 30/30\n",
            "12/12 [==============================] - 5s 387ms/step - loss: 0.0601 - accuracy: 0.9766 - val_loss: 0.6654 - val_accuracy: 0.7656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uz6x8lI2nhP"
      },
      "source": [
        "**SQUEEZENET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2UITja42p82",
        "outputId": "a32ebe4a-fd56-427a-ef84-2b44eea9a4a6"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQCa0yiJ2zc2",
        "outputId": "12ceed70-6a02-4ff4-c52c-ea06659c20d6"
      },
      "source": [
        "bnmomemtum=0.9\n",
        "def fire(x, squeeze, expand):\n",
        "  y  = tf.keras.layers.Conv2D(filters=squeeze, kernel_size=1, activation='relu', padding='same')(x)\n",
        "  y = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y)\n",
        "  y1 = tf.keras.layers.Conv2D(filters=expand//2, kernel_size=1, activation='relu', padding='same')(y)\n",
        "  y1 = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y1)\n",
        "  y3 = tf.keras.layers.Conv2D(filters=expand//2, kernel_size=3, activation='relu', padding='same')(y)\n",
        "  y3 = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y3)\n",
        "  return tf.keras.layers.concatenate([y1, y3])\n",
        "\n",
        "def fire_module(squeeze, expand):\n",
        "  return lambda x: fire(x, squeeze, expand)\n",
        "\n",
        "x = tf.keras.layers.Input(shape=[128,128, 3]) # input is 192x192 pixels RGB\n",
        "\n",
        "y = tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', use_bias=True, activation='relu')(x)\n",
        "y = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y)\n",
        "y = fire_module(24, 48)(y)\n",
        "y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
        "y = fire_module(48, 96)(y)\n",
        "y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
        "y = fire_module(64, 128)(y)\n",
        "y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
        "y = fire_module(48, 96)(y)\n",
        "y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)\n",
        "y = fire_module(24, 48)(y)\n",
        "y = tf.keras.layers.GlobalAveragePooling2D()(y)\n",
        "y = tf.keras.layers.Dense(3, activation='softmax')(y)\n",
        "\n",
        "model = tf.keras.Model(x, y)\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss= 'categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)          [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 128, 32  896         ['input_10[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 128, 128, 32  128        ['conv2d_4[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 128, 128, 24  792         ['batch_normalization_6[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 128, 128, 24  96         ['conv2d_5[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 128, 128, 24  600         ['batch_normalization_7[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 128, 128, 24  5208        ['batch_normalization_7[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 128, 128, 24  96         ['conv2d_6[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 128, 128, 24  96         ['conv2d_7[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 128, 128, 48  0           ['batch_normalization_8[0][0]',  \n",
            "                                )                                 'batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 48)  0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 64, 64, 48)   2352        ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 64, 64, 48)  192         ['conv2d_8[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 64, 64, 48)   2352        ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 64, 64, 48)   20784       ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 64, 64, 48)  192         ['conv2d_9[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 64, 64, 48)  192         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 96)   0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 96)  0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 64)   6208        ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 32, 32, 64)  256         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 64)   4160        ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 32, 32, 64)   36928       ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 32, 32, 64)  256         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 32, 32, 64)  256         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 32, 32, 128)  0           ['batch_normalization_14[0][0]', \n",
            "                                                                  'batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 128)  0          ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 48)   6192        ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 48)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 48)   2352        ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 48)   20784       ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 48)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 48)  192         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]', \n",
            "                                                                  'batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 96)    0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 8, 8, 24)     2328        ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 8, 8, 24)    96          ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 8, 8, 24)     600         ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 8, 8, 24)     5208        ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 8, 8, 24)    96          ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 8, 8, 24)    96          ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 8, 8, 48)     0           ['batch_normalization_20[0][0]', \n",
            "                                                                  'batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3 (Gl  (None, 48)          0           ['concatenate_4[0][0]']          \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 3)            147         ['global_average_pooling2d_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 120,515\n",
            "Trainable params: 119,203\n",
            "Non-trainable params: 1,312\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QNL7N1zrPAu",
        "outputId": "42801349-53ea-4e1c-e576-a87f267a60bf"
      },
      "source": [
        "x_train,y_train = next(train_generator)\n",
        "x_test,y_test = next(validation_generator)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 128, 128, 3)\n",
            "(32, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyyXUF_X3tPc",
        "outputId": "ec96ab19-fb11-47c1-a01e-d44e680cd7fc"
      },
      "source": [
        "#for fitting the model\n",
        "from keras.callbacks import EarlyStopping\n",
        "EPOCHS_SQ = 30\n",
        "\n",
        "STEPS = train_generator.samples//train_generator.batch_size\n",
        "VAL_STEPS = validation_generator.samples//validation_generator.batch_size\n",
        "\n",
        "SQ_STOP = EarlyStopping(\n",
        "    monitor='val_accuracy', \n",
        "    mode='max',\n",
        "    patience=7,\n",
        "    verbose = 2,\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=STEPS,\n",
        "    epochs=EPOCHS_SQ,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=VAL_STEPS,\n",
        "    callbacks=[SQ_STOP]\n",
        ")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 25s 837ms/step - loss: 0.8742 - accuracy: 0.6349 - val_loss: 1.6432 - val_accuracy: 0.3203\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 3s 230ms/step - loss: 0.4998 - accuracy: 0.8776 - val_loss: 2.2807 - val_accuracy: 0.2969\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 5s 400ms/step - loss: 0.3670 - accuracy: 0.8968 - val_loss: 1.2868 - val_accuracy: 0.4062\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 3s 273ms/step - loss: 0.2598 - accuracy: 0.9524 - val_loss: 0.6583 - val_accuracy: 0.7500\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 3s 256ms/step - loss: 0.2012 - accuracy: 0.9630 - val_loss: 0.4048 - val_accuracy: 0.8750\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 3s 228ms/step - loss: 0.1360 - accuracy: 0.9762 - val_loss: 0.4120 - val_accuracy: 0.8750\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 6s 483ms/step - loss: 0.1104 - accuracy: 0.9868 - val_loss: 0.4281 - val_accuracy: 0.8359\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 3s 286ms/step - loss: 0.0999 - accuracy: 0.9868 - val_loss: 0.3168 - val_accuracy: 0.8828\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 3s 285ms/step - loss: 0.1011 - accuracy: 0.9841 - val_loss: 0.4008 - val_accuracy: 0.8203\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 3s 251ms/step - loss: 0.0894 - accuracy: 0.9841 - val_loss: 0.3948 - val_accuracy: 0.8672\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 3s 227ms/step - loss: 0.0713 - accuracy: 0.9921 - val_loss: 0.9784 - val_accuracy: 0.6094\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 3s 258ms/step - loss: 0.0739 - accuracy: 0.9894 - val_loss: 0.5946 - val_accuracy: 0.7500\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 3s 230ms/step - loss: 0.0554 - accuracy: 0.9947 - val_loss: 0.2229 - val_accuracy: 0.9297\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 4s 358ms/step - loss: 0.1209 - accuracy: 0.9656 - val_loss: 0.2710 - val_accuracy: 0.9297\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 3s 276ms/step - loss: 0.0808 - accuracy: 0.9788 - val_loss: 0.4352 - val_accuracy: 0.8281\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 3s 263ms/step - loss: 0.0749 - accuracy: 0.9841 - val_loss: 0.3883 - val_accuracy: 0.8906\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 3s 256ms/step - loss: 0.0522 - accuracy: 0.9947 - val_loss: 0.8089 - val_accuracy: 0.7188\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 3s 253ms/step - loss: 0.0607 - accuracy: 0.9815 - val_loss: 0.4162 - val_accuracy: 0.8281\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 3s 257ms/step - loss: 0.0466 - accuracy: 0.9894 - val_loss: 0.4849 - val_accuracy: 0.8438\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 0.9844Restoring model weights from the end of the best epoch: 13.\n",
            "12/12 [==============================] - 3s 234ms/step - loss: 0.0589 - accuracy: 0.9844 - val_loss: 0.2816 - val_accuracy: 0.9141\n",
            "Epoch 20: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fih9YRLtB5m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "f8bafba3-0deb-4521-a861-d3b4330d988a"
      },
      "source": [
        "model.save('sq_model.h5')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-bac1b3cf9b1a>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mexport_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Deep Learning Models'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sq_model.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# model.save('sq_model.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1238\u001b[0m   \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementWriteApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SAVE_V2_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m   \u001b[0msave_and_return_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementWrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[0;32m-> 1276\u001b[0;31m       _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0m\u001b[1;32m   1277\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[1;32m   1278\u001b[0m       constants.SAVED_MODEL_SCHEMA_VERSION)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_meta_graph_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1388\u001b[0m   \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"Expected an object of type `Trackable`, such as `tf.Module` or a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;34mf\"subclass of the `Trackable` class, for export. Got {obj} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected an object of type `Trackable`, such as `tf.Module` or a subclass of the `Trackable` class, for export. Got sq_model.h5 with type <class 'str'>."
          ]
        }
      ]
    }
  ]
}